# -*- coding: utf-8 -*-
"""A Hybrid Online Classification and LLM Based Model for Threat Intelligence.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OAn_CvMOiXd-HjJ6zZz_H7Vyyjf2cJsd

***Data Loading & Pre-Processing:***
"""

import pandas as pd

df_wed = pd.read_csv("/content/drive/MyDrive/Wednesday-workingHours.pcap_ISCX.csv")

print("Wednesday shape:", df_wed.shape)

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

df_wed.dtypes

df_wed[' Label'].unique()

# Missing Values
df_wed.isnull().sum()

df_wed['Flow Bytes/s'] = df_wed['Flow Bytes/s'].fillna(0)

# Summary Statistics (mean, std, min, max)
df_wed.describe()

# Class Distribution (Label)
df_wed[' Label'].value_counts()

"""***Online Machine Learning (Classification):***

***Streaming with iterrows()***



*   It provides the records one by one, similar to real-time data.
*   The order of rows reflects the temporal sequence.
*   It uses very little memory since only a single record is processed at a time.
"""

!pip install river

!pip install -U river

import pandas as pd
from river.tree import HoeffdingTreeClassifier
from river import metrics

# Online Model
model = HoeffdingTreeClassifier()

# Online Accuracy Metric
metric = metrics.Accuracy()

print("Model initialized as:", model)

LABEL_COL = " Label"

numeric_cols = df_wed.select_dtypes(include=["int64","float64","int32","float32"]).columns.tolist()
feature_cols = [c for c in numeric_cols if c != LABEL_COL]

accuracies = []

for i, (_, row) in enumerate(df_wed.iterrows()):

    xi = row[feature_cols].to_dict()
    yi = row[LABEL_COL]

    # Predict
    y_pred = model.predict_one(xi)

    if y_pred is not None:
        metric.update(yi, y_pred)
        accuracies.append(metric.get())
    else:
        accuracies.append(metric.get())


    model.learn_one(xi, yi)

    if (i+1) % 1000 == 0:
        print(f"Row {i+1} → Accuracy: {metric.get():.4f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))
plt.plot(accuracies, linewidth=1, color='blue')
plt.title("Online Accuracy Over Time", fontsize=14)
plt.xlabel("Sample Index", fontsize=12)
plt.ylabel("Accuracy", fontsize=12)
plt.grid(alpha=0.3)
plt.show()

import numpy as np

window = 5000
ma = np.convolve(accuracies, np.ones(window)/window, mode='valid')

plt.figure(figsize=(12,5))
plt.plot(ma, color='red')
plt.title("Moving Average of Online Accuracy", fontsize=14)
plt.xlabel("Sample Index", fontsize=12)
plt.ylabel("Smoothed Accuracy", fontsize=12)

plt.ylim(0.8, 1.0)
plt.grid(alpha=0.3)
plt.show()

from river import metrics

cm = metrics.ConfusionMatrix()

for i, (_, row) in enumerate(df_wed.iterrows()):

    xi = row[feature_cols].to_dict()
    yi = row[LABEL_COL]

    y_pred = model.predict_one(xi)


    if y_pred is not None:
        cm.update(yi, y_pred)


    model.learn_one(xi, yi)

    if (i+1) % 20000 == 0:
        print(f"Processed {i+1} rows...")

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


if len(cm.classes) == 0:
    print("Confusion matrix is empty — no predictions made yet.")
else:

    labels = list(cm.classes)


    cm_matrix = pd.DataFrame(0, index=labels, columns=labels)


    for true_label, preds in cm.data.items():
        for pred_label, count in preds.items():
            cm_matrix.loc[true_label, pred_label] = count


    plt.figure(figsize=(12,7))
    sns.heatmap(cm_matrix, annot=True, fmt="d", cmap="Blues")
    plt.title("Confusion Matrix (Online Streaming Classifier)")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

import pandas as pd


labels = list(cm.classes)


cm_raw = pd.DataFrame(0, index=labels, columns=labels)


for true_label, preds in cm.data.items():
    for pred_label, count in preds.items():
        cm_raw.loc[true_label, pred_label] = count

print("Raw Confusion Matrix:")
cm_raw

cm_percent = cm_raw.div(cm_raw.sum(axis=1), axis=0) * 100
cm_percent = cm_percent.round(2)   #

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(14, 8))
sns.heatmap(cm_percent, annot=True, fmt=".2f", cmap="Blues")
plt.title("Normalized Confusion Matrix (%) — Online Streaming Classifier")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

from collections import Counter

labels_seen = []

for i, (_, row) in enumerate(df_wed.iterrows()):
    yi = row[LABEL_COL]
    labels_seen.append(yi)

from collections import Counter
import matplotlib.pyplot as plt

counts = Counter(labels_seen)

plt.figure(figsize=(10,4))
plt.bar(counts.keys(), counts.values())
plt.xticks(rotation=90)
plt.title("Class Distribution in Stream")
plt.show()

"""***TI generation pipeline:***"""

events_list = []

for i, row in df_wed.iterrows():

    x = row[feature_cols].to_dict()
    y = row[LABEL_COL]              # true label

    pred = model.predict_one(x)     # predicted label


    if y != "BENIGN":
        events_list.append({
            "index": i,
            "true_label": y,
            "predicted_label": pred,
            "features": x
        })


    model.learn_one(x, y)

import random

sample_events = random.sample(events_list, 3)

import json

def build_event_json(event):
    return json.dumps({
        "event_id": event["index"],
        "true_label": event["true_label"],
        "predicted_label": event["predicted_label"],
        "features": event["features"]
    }, indent=2)

TI_PROMPT = """
You are a Cyber Threat Intelligence (CTI) analyst.
Your task is to analyze the following network flow record and generate
a structured, concise, and strictly evidence-based TI report.

=====================
EVENT DATA (JSON)
=====================
{event_json}

=====================
STRICT ANALYSIS RULES
=====================
1. You may ONLY use the fields explicitly present in the event JSON:
   - Flow ID, Timestamp, Protocol
   - Source IP, Source Port
   - Destination IP, Destination Port
   - Flow Duration, Flow Bytes/s, Flow Packets/s
   - Total Fwd Packets, Total Bwd Packets
   - Total Length of Fwd Packets, Total Length of Bwd Packets
   - Fwd/Bwd Packet Length (Max/Min/Mean/Std)
   - Packet Length (Min/Max/Mean/Std/Variance)
   - Flow IAT (Mean/Std/Min/Max)
   - Fwd/Bwd IAT (Total/Mean/Std/Min/Max)
   - All flag fields (SYN, ACK, PSH, URG, FIN, CWE, ECE, etc.)
   - Window metrics, segment size, subflow statistics
   - Active/Idle metrics
   - The "Label" field (attack type or BENIGN)

2. STRICTLY FORBIDDEN:
   - No assumptions, no speculation, no inferred behavior.
   - No new IPs, ports, domains, URLs, hostnames.
   - No payload descriptions.
   - No CVE, malware, tool names, campaign names.
   - No attribution of any kind (country, actor, intent).
   - No invented IoCs.

3. If the label indicates BENIGN, output:
   "Based on the available data, this event does not indicate malicious activity."

4. TI report MUST follow this exact structure (no additions):
   1. Executive Summary (state only what the numeric evidence directly shows)
   2. Threat Classification
      - Label: {Label_from_JSON}
      - Attack Definition: {One-sentence definition based strictly on flow behavior}
      - Behavioral Evidence: {Which numeric patterns support the definition}
   3. Key Indicators (only restate values found in the JSON)
   4. MITRE ATT&CK Mapping
      - Only if the traffic pattern strictly matches a documented behavioral signature.

   5. Impact Assessment
      - Only describe effects directly inferable from numeric metrics
        (e.g., "high backward packet size", "long flow duration").
   6. You must select mitigation items. Selection MUST follow these rules:
      (A) Mitigations MUST be chosen ONLY from the CIS-based mitigation pool listed below.
      (B) Selection MUST be based on BOTH: - The "Label" (attack type), and - The numerical traffic evidence present in the JSON
      (e.g., Flow Duration, packet sizes, ratios, flags, IAT values, active/idle metrics).
      (C) You MUST NOT create, reword, or modify any mitigation.
      (D) You MUST NOT output more or fewer than 5 items.
      (E) If a mitigation does not appear in the pool, you MUST NOT use it.
      ---- CIS Mitigation Pool ----
      M1. Implement network rate limiting and bandwidth throttling.
      M2. Enforce firewall filtering and network segmentation.
      M3. Enable intrusion detection/prevention (IDS/IPS).
      M4. Apply anomaly-based detection on flow metrics.
      M5. Maintain secure configurations for network services.
      M6. Limit exposure of services through access control.
      M7. Collect and review detailed network logs.
      M8. Monitor directional traffic volume and byte ratios.
      M9. Enforce resource consumption thresholds per connection.
      M10. Use WAF (Web Application Firewall) for HTTP-based flows.
      M11. Apply DoS/DDoS protection and traffic scrubbing.
      M12. Monitor long-duration or high-packet-rate flows.
      M13. Detect abnormal packet-size distributions.
      M14. Limit repeated connections from a single source.
      M15. Inspect flow timing irregularities.



5. ZERO hallucination. ZERO extrapolation. ZERO speculation.

6. Maintain logging and visibility on directional byte ratios.

=====================
OUTPUT FORMAT
=====================
TI Report:
"""

from openai import OpenAI
client = OpenAI(api_key="YOUR_OPENAI_API_KEY")

def generate_ti_report(event):
    event_json = build_event_json(event)
    prompt = TI_PROMPT.format(event_json=event_json)

    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message["content"]

"""Test:"""

pip install PyPDF2

import PyPDF2

def read_pdf(path):
    reader = PyPDF2.PdfReader(path)
    text = ""
    for page in reader.pages:
        extracted = page.extract_text()
        if extracted:
            text += extracted + "\n"
    return text

doc1 = read_pdf("/content/drive/MyDrive/Final Report-1.pdf")
doc2 = read_pdf("/content/drive/MyDrive/Final-Report-2.pdf")

print(doc1[:500])
print(doc2[:500])

from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

emb1 = model.encode(doc1, convert_to_tensor=True)
emb2 = model.encode(doc2, convert_to_tensor=True)

similarity = util.cos_sim(emb1, emb2).item()
print("Semantic similarity:", similarity)

import PyPDF2

def read_pdf(path):
    reader = PyPDF2.PdfReader(path)
    text = ""
    for page in reader.pages:
        extracted = page.extract_text()
        if extracted:
            text += extracted + "\n"
    return text

doc1 = read_pdf("/content/drive/MyDrive/without-prompt.pdf")
doc2 = read_pdf("/content/drive/MyDrive/TI-Report-Without Prompt-2.pdf")

print(doc1[:500])
print(doc2[:500])

from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

emb1 = model.encode(doc1, convert_to_tensor=True)
emb2 = model.encode(doc2, convert_to_tensor=True)

similarity = util.cos_sim(emb1, emb2).item()
print("Semantic similarity:", similarity)